{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"./data/*/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_data(path):\n",
    "    print(path)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    # regex for stripping out the leading \"Subject:\" and any spaces after it\n",
    "    subject_regex = re.compile(r\"^Subject:\\s+\")\n",
    "\n",
    "    # glob.glob returns every filename that matches the wildcarded path\n",
    "    for fn in glob.glob(path):\n",
    "        is_spam = \"ham\" not in fn\n",
    "        try:\n",
    "            with open(fn,'r', encoding=\"utf-8\") as file:\n",
    "                for line in file:\n",
    "                    if line.startswith(\"Subject:\"):\n",
    "                        subject = subject_regex.sub(\"\", line).strip()\n",
    "                        data.append((subject, is_spam))\n",
    "        except UnicodeDecodeError as e:\n",
    "            pass\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/*/*\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4965, 3184)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_subject_data(data_path)\n",
    "corpus = set()\n",
    "for text in data:\n",
    "    corpus = corpus | set([characters.lower() for characters in text[0].split()])\n",
    "\n",
    "corupus_dict = {}\n",
    "for i, v in enumerate(corpus):\n",
    "    corupus_dict[v] = i\n",
    "\n",
    "corpus_index = []\n",
    "for text in data:\n",
    "    bag_of_word_index = []\n",
    "    for word in [characters.lower() for characters in text[0].split()]:\n",
    "        bag_of_word_index.append(corupus_dict[word])\n",
    "    corpus_index.append(bag_of_word_index)\n",
    "\n",
    "len(corpus), len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ...,  True,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_data = []\n",
    "for text in data:\n",
    "    y_data.append(text[1])\n",
    "y_data = np.array(y_data)\n",
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3184, 4965)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = np.zeros((len(data), len(corpus)))\n",
    "for i, c_index in enumerate(corpus_index):\n",
    "    x_data[i][c_index] = 1\n",
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sungchulchoi/miniconda3/envs/ml_scratch/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "crossvalidation = KFold(n=x_data.shape[0], n_folds=10,\n",
    " shuffle=True, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89918968474596317"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.mean(cross_val_score(clf, x_data, y_data,\n",
    "    scoring='accuracy', cv=crossvalidation, n_jobs=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth  5 : 0.889443228643\n",
      "Depth  6 : 0.893841801226\n",
      "Depth  7 : 0.896041087518\n",
      "Depth  8 : 0.89824234538\n",
      "Depth  9 : 0.901069576704\n",
      "Depth  10 : 0.905775714201\n",
      "Depth  11 : 0.90609017961\n",
      "Depth  12 : 0.908602945526\n",
      "Depth  13 : 0.907975000493\n",
      "Depth  14 : 0.910799274462\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "for depth in range (5,15):\n",
    "    tree_classifier = DecisionTreeClassifier(\n",
    "        max_depth=depth, random_state=0)\n",
    "    score = np.mean(cross_val_score(tree_classifier, x_data, y_data,\n",
    "        scoring='accuracy', cv=crossvalidation, n_jobs=1))\n",
    "    print(\"Depth \", depth, \":\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92965339800082825"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model, datasets\n",
    "logreg = linear_model.LogisticRegression(fit_intercept=True,max_iter=1000)\n",
    "score = np.mean(cross_val_score(logreg, x_data, y_data,\n",
    "        scoring='accuracy', cv=crossvalidation, n_jobs=1))\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth  2 : 0.910799274462\n",
      "Depth  3 : 0.910799274462\n",
      "Depth  4 : 0.910799274462\n",
      "Depth  5 : 0.910799274462\n",
      "Depth  6 : 0.910799274462\n",
      "Depth  7 : 0.910799274462\n",
      "Depth  8 : 0.910799274462\n",
      "Depth  9 : 0.910799274462\n",
      "Depth  10 : 0.910799274462\n",
      "Depth  11 : 0.910799274462\n",
      "Depth  12 : 0.910799274462\n",
      "Depth  13 : 0.910799274462\n",
      "Depth  14 : 0.910799274462\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "for depth in range (2,15):\n",
    "    clf = RandomForestClassifier(max_depth=depth, random_state=0, n_estimators=10, n_jobs=4)\n",
    "    score = np.mean(cross_val_score(tree_classifier, x_data, y_data,\n",
    "        scoring='accuracy', cv=crossvalidation, n_jobs=1))\n",
    "    print(\"Depth \", depth, \":\", score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
